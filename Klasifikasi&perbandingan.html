
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Over-Sampling &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/costom.css?v=c5ad1e6b" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Klasifikasi&perbandingan';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Preprocessing" href="preposesing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/profil.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/profil.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Profil Mahasiswa
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Business_Understanding_iris.html">Business Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="Data_Understanding_iris.html">Data Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="preposesing.html">Preprocessing</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Over-Sampling</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FKlasifikasi&perbandingan.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Klasifikasi&perbandingan.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Over-Sampling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-machine-learning">Model Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library">Import Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemanggilan-data-ecoli-dari-database-aiven">Pemanggilan data ecoli dari database Aiven</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-awal-distribusi-kelas">Eksplorasi Awal &amp; Distribusi Kelas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persiapan-data">Persiapan Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-1-data-belum-diseimbangkan">1. <strong>Eksperimen 1 – Data Belum Diseimbangkan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-belum-diseimbangkan"><strong>Naive Bayes – Data Belum Diseimbangkan</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-belum-diseimbangkan"><strong>Random Forest – Data Belum Diseimbangkan</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-belum-diseimbangkan"><strong>Bagging Classifier – Data Belum Diseimbangkan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-dengan-naive-bayes">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-dengan-decision-tree">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-2-data-seimbang-dengan-smote"><strong>2. Eksperimen 2 – Data Seimbang dengan SMOTE</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-dengan-smote">PCA dengan SMOTE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-seimbang-smote"><strong>Naive Bayes – Data Seimbang (SMOTE)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-seimbang-smote"><strong>Random Forest – Data Seimbang (SMOTE)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-seimbang-smote"><strong>Bagging Classifier – Data Seimbang (SMOTE)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-3-adasyn"><strong>3. Eksperimen 3 – ADASYN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-sesudah-adasyn">PCA sesudah ADASYN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-seimbang-adasyn"><strong>Naive Bayes – Data Seimbang (ADASYN)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-seimbang-adasyn"><strong>Random Forest – Data Seimbang (ADASYN)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-seimbang-adasyn"><strong>Bagging Classifier – Data Seimbang (ADASYN)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-hasil-klasifikasi-data-asli-vs-smote-vs-adasyn">Perbandingan Hasil Klasifikasi – Data Asli vs SMOTE vs ADASYN</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="over-sampling">
<h1>Over-Sampling<a class="headerlink" href="#over-sampling" title="Link to this heading">#</a></h1>
<p>Oversampling adalah teknik yang digunakan untuk menangani ketidakseimbangan kelas (class imbalance) dalam dataset. Ketika salah satu kelas memiliki jumlah sampel jauh lebih sedikit dibanding kelas lain, model cenderung bias terhadap kelas mayoritas.</p>
<section id="model-machine-learning">
<h2>Model Machine Learning<a class="headerlink" href="#model-machine-learning" title="Link to this heading">#</a></h2>
<p><strong>Naive Bayes</strong></p>
<ul class="simple">
<li><p>Algoritma probabilistik berbasis <strong>Teorema Bayes</strong>.</p></li>
<li><p>Asumsi: fitur saling independen.</p></li>
<li><p>Cepat, sederhana, cocok untuk data teks.</p></li>
<li><p>Kurang akurat jika fitur saling bergantung.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Random Forest</strong></p>
<ul class="simple">
<li><p><strong>Ensemble</strong> dari banyak Decision Tree.</p></li>
<li><p>Menggunakan <strong>bootstrap sampling</strong> + pemilihan fitur acak.</p></li>
<li><p>Akurat, tahan <em>overfitting</em>, stabil.</p></li>
<li><p>Lebih lambat, sulit diinterpretasi.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Bagging Classifier</strong></p>
<ul class="simple">
<li><p><strong>Bagging Classifier</strong> adalah algoritma <em>ensemble learning</em> berbasis metode <strong>Bagging (Bootstrap Aggregating)</strong> untuk klasifikasi.<br />
Prinsipnya: melatih beberapa model (biasanya Decision Tree) pada data subset acak, lalu hasil prediksi digabung dengan voting mayoritas.</p></li>
<li><p>Melatih beberapa model pada subset data berbeda.</p></li>
<li><p>Mengurangi <em>overfitting</em>, lebih stabil.</p></li>
<li><p>Butuh komputasi lebih banyak.</p></li>
</ul>
</section>
<section id="import-library">
<h2>Import Library<a class="headerlink" href="#import-library" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mysql.connector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">imblearn.over_sampling</span><span class="w"> </span><span class="kn">import</span> <span class="n">SMOTE</span><span class="p">,</span> <span class="n">ADASYN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="pemanggilan-data-ecoli-dari-database-aiven">
<h2>Pemanggilan data ecoli dari database Aiven<a class="headerlink" href="#pemanggilan-data-ecoli-dari-database-aiven" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mysql.connector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># arahkan ke file .env yang benar</span>
<span class="n">load_dotenv</span><span class="p">(</span><span class="n">dotenv_path</span><span class="o">=</span><span class="s2">&quot;/workspaces/PSD1/Tugas/.env&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_env</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Environment variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> tidak ditemukan di .env&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value</span>

<span class="c1"># Ambil variabel dari .env</span>
<span class="n">host</span> <span class="o">=</span> <span class="n">get_env</span><span class="p">(</span><span class="s2">&quot;DB_HOST&quot;</span><span class="p">)</span>
<span class="n">port</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_env</span><span class="p">(</span><span class="s2">&quot;DB_PORT&quot;</span><span class="p">))</span>
<span class="n">user</span> <span class="o">=</span> <span class="n">get_env</span><span class="p">(</span><span class="s2">&quot;DB_USER&quot;</span><span class="p">)</span>
<span class="n">password</span> <span class="o">=</span> <span class="n">get_env</span><span class="p">(</span><span class="s2">&quot;DB_PASSWORD&quot;</span><span class="p">)</span>
<span class="n">database</span> <span class="o">=</span> <span class="n">get_env</span><span class="p">(</span><span class="s2">&quot;DB_NAME&quot;</span><span class="p">)</span>

<span class="c1"># Koneksi ke database</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">mysql</span><span class="o">.</span><span class="n">connector</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="n">password</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="n">database</span>
<span class="p">)</span>

<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM ecoli&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data awal:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data awal:
  sequence_name   mcg   gvh   lip  chg   aac  alm1  alm2 class
0     AAS_ECOLI  0.44  0.52  0.48  0.5  0.43  0.47  0.54    im
1     AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35    cp
2    ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44    cp
3    ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46    cp
4    ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36    cp
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_39407/2402679444.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, conn)
</pre></div>
</div>
</div>
</div>
</section>
<section id="eksplorasi-awal-distribusi-kelas">
<h2>Eksplorasi Awal &amp; Distribusi Kelas<a class="headerlink" href="#eksplorasi-awal-distribusi-kelas" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distribusi kelas asli:&quot;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribusi kelas asli: Counter({&#39;cp&#39;: 143, &#39;im&#39;: 77, &#39;pp&#39;: 52, &#39;imU&#39;: 35, &#39;om&#39;: 20, &#39;omL&#39;: 5, &#39;imS&#39;: 2, &#39;imL&#39;: 2})
</pre></div>
</div>
</div>
</div>
</section>
<section id="persiapan-data">
<h2>Persiapan Data<a class="headerlink" href="#persiapan-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sequence_name&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X = fitur numerik, y = label</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape X:&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape y:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># PCA ke 2 dimensi</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot hasil PCA</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_pca</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">X_pca</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PCA Component 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PCA Component 2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Visualization of Ecoli Dataset&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape X: (336, 7)
Shape y: (336,)
</pre></div>
</div>
<img alt="_images/08d75795316b9d3a6493f338233433a6f0aa2a364cb06ab4e1fb9ecaf4ee487e.png" src="_images/08d75795316b9d3a6493f338233433a6f0aa2a364cb06ab4e1fb9ecaf4ee487e.png" />
</div>
</div>
</section>
<section id="eksperimen-1-data-belum-diseimbangkan">
<h2>1. <strong>Eksperimen 1 – Data Belum Diseimbangkan</strong><a class="headerlink" href="#eksperimen-1-data-belum-diseimbangkan" title="Link to this heading">#</a></h2>
<section id="naive-bayes-data-belum-diseimbangkan">
<h3><strong>Naive Bayes – Data Belum Diseimbangkan</strong><a class="headerlink" href="#naive-bayes-data-belum-diseimbangkan" title="Link to this heading">#</a></h3>
<p>Pada tahap ini, kita menggunakan <strong>Naive Bayes (GaussianNB)</strong> untuk melakukan klasifikasi pada dataset asli <em>tanpa penyeimbangan kelas</em>.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Pisahkan data menjadi training dan testing (80:20, stratified).</p></li>
<li><p>Latih model Naive Bayes pada data training.</p></li>
<li><p>Evaluasi model dengan data testing menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pisahkan data (belum seimbang)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi model Naive Bayes</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Latih model</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Naive Bayes (data asli):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Naive Bayes (data asli): 0.8529411764705882

Classification Report:
               precision    recall  f1-score   support

          cp       0.97      1.00      0.98        29
          im       0.85      0.69      0.76        16
         imU       0.67      0.57      0.62         7
          om       1.00      0.50      0.67         4
         omL       0.50      1.00      0.67         1
          pp       0.73      1.00      0.85        11

    accuracy                           0.85        68
   macro avg       0.79      0.79      0.76        68
weighted avg       0.86      0.85      0.85        68


Confusion Matrix:
 [[29  0  0  0  0  0]
 [ 1 11  2  0  0  2]
 [ 0  2  4  0  0  1]
 [ 0  0  0  2  1  1]
 [ 0  0  0  0  1  0]
 [ 0  0  0  0  0 11]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-data-belum-diseimbangkan">
<h3><strong>Random Forest – Data Belum Diseimbangkan</strong><a class="headerlink" href="#random-forest-data-belum-diseimbangkan" title="Link to this heading">#</a></h3>
<p>Pada tahap ini, kita menggunakan <strong>Random Forest Classifier</strong> untuk melakukan klasifikasi pada dataset asli <em>tanpa penyeimbangan kelas</em>.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Pisahkan data menjadi training dan testing (80:20, stratified).</p></li>
<li><p>Latih model Random Forest pada data training.</p></li>
<li><p>Evaluasi model dengan data testing menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pisahkan data (belum seimbang)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi Random Forest</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>      <span class="c1"># jumlah pohon</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span>      <span class="c1"># karena data belum seimbang, kita biarkan default</span>
<span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Random Forest (data asli):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Random Forest (data asli): 0.8970588235294118

Classification Report:
               precision    recall  f1-score   support

          cp       0.97      1.00      0.98        29
          im       0.79      0.94      0.86        16
         imU       0.75      0.43      0.55         7
          om       1.00      0.75      0.86         4
         omL       1.00      1.00      1.00         1
          pp       0.91      0.91      0.91        11

    accuracy                           0.90        68
   macro avg       0.90      0.84      0.86        68
weighted avg       0.90      0.90      0.89        68


Confusion Matrix:
 [[29  0  0  0  0  0]
 [ 0 15  1  0  0  0]
 [ 0  4  3  0  0  0]
 [ 0  0  0  3  0  1]
 [ 0  0  0  0  1  0]
 [ 1  0  0  0  0 10]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="bagging-classifier-data-belum-diseimbangkan">
<h3><strong>Bagging Classifier – Data Belum Diseimbangkan</strong><a class="headerlink" href="#bagging-classifier-data-belum-diseimbangkan" title="Link to this heading">#</a></h3>
<p>Pada tahap ini, kita menggunakan <strong>Bagging Classifier</strong> untuk melakukan klasifikasi pada dataset asli <em>tanpa penyeimbangan kelas</em>.<br />
Bagging akan dilatih dengan dua skenario:</p>
<ol class="arabic simple">
<li><p>Menggunakan <strong>Naive Bayes</strong> sebagai base estimator.</p></li>
<li><p>Menggunakan <strong>Decision Tree</strong> sebagai base estimator (default yang paling sering digunakan).</p></li>
</ol>
<p>Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Pisahkan data menjadi training dan testing (80:20, stratified).</p></li>
<li><p>Latih model Bagging dengan base estimator yang dipilih.</p></li>
<li><p>Evaluasi model menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<section id="bagging-dengan-naive-bayes">
<h4>Bagging dengan Naive Bayes<a class="headerlink" href="#bagging-dengan-naive-bayes" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Base estimator = Naive Bayes</span>
<span class="n">bag_nb</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">bag_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (base Naive Bayes, data asli):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (base Naive Bayes, data asli): 0.8382352941176471

Classification Report:
               precision    recall  f1-score   support

          cp       0.97      1.00      0.98        29
          im       0.73      0.69      0.71        16
         imU       0.60      0.43      0.50         7
          om       1.00      0.50      0.67         4
         omL       0.50      1.00      0.67         1
          pp       0.79      1.00      0.88        11

    accuracy                           0.84        68
   macro avg       0.76      0.77      0.73        68
weighted avg       0.84      0.84      0.83        68


Confusion Matrix:
 [[29  0  0  0  0  0]
 [ 1 11  2  0  0  2]
 [ 0  4  3  0  0  0]
 [ 0  0  0  2  1  1]
 [ 0  0  0  0  1  0]
 [ 0  0  0  0  0 11]]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
</pre></div>
</div>
</div>
</div>
</section>
<section id="bagging-dengan-decision-tree">
<h4>Bagging dengan Decision Tree<a class="headerlink" href="#bagging-dengan-decision-tree" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Base estimator = Decision Tree</span>
<span class="n">bag_dt</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">bag_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (base Decision Tree, data asli):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (base Decision Tree, data asli): 0.8823529411764706

Classification Report:
               precision    recall  f1-score   support

          cp       0.97      1.00      0.98        29
          im       0.79      0.94      0.86        16
         imU       0.60      0.43      0.50         7
          om       1.00      0.50      0.67         4
         omL       1.00      1.00      1.00         1
          pp       0.91      0.91      0.91        11

    accuracy                           0.88        68
   macro avg       0.88      0.80      0.82        68
weighted avg       0.88      0.88      0.87        68


Confusion Matrix:
 [[29  0  0  0  0  0]
 [ 0 15  1  0  0  0]
 [ 0  4  3  0  0  0]
 [ 0  0  1  2  0  1]
 [ 0  0  0  0  1  0]
 [ 1  0  0  0  0 10]]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="eksperimen-2-data-seimbang-dengan-smote">
<h2><strong>2. Eksperimen 2 – Data Seimbang dengan SMOTE</strong><a class="headerlink" href="#eksperimen-2-data-seimbang-dengan-smote" title="Link to this heading">#</a></h2>
<p>Pada eksperimen kedua, dataset yang sebelumnya tidak seimbang akan diseimbangkan menggunakan <strong>SMOTE (Synthetic Minority Oversampling Technique)</strong>.<br />
SMOTE bekerja dengan cara membuat data sintetis baru untuk kelas minoritas berdasarkan interpolasi antar tetangga terdekat.</p>
<p>Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Terapkan SMOTE pada data asli.</p></li>
<li><p>Periksa kembali distribusi kelas setelah SMOTE.</p></li>
<li><p>Simpan data hasil balancing untuk digunakan pada klasifikasi berikutnya (Naive Bayes, Random Forest, Bagging).</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Terapkan SMOTE</span>
<span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">k_neighbors</span><span class="o">=</span><span class="mi">1</span> <span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distribusi sebelum SMOTE:&quot;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distribusi sesudah SMOTE:&quot;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_sm</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribusi sebelum SMOTE: Counter({&#39;cp&#39;: 143, &#39;im&#39;: 77, &#39;pp&#39;: 52, &#39;imU&#39;: 35, &#39;om&#39;: 20, &#39;omL&#39;: 5, &#39;imS&#39;: 2, &#39;imL&#39;: 2})
Distribusi sesudah SMOTE: Counter({&#39;im&#39;: 143, &#39;cp&#39;: 143, &#39;pp&#39;: 143, &#39;imU&#39;: 143, &#39;imS&#39;: 143, &#39;om&#39;: 143, &#39;imL&#39;: 143, &#39;omL&#39;: 143})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Sebelum SMOTE</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribusi Kelas Sebelum SMOTE&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="c1"># Sesudah SMOTE</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_sm</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_sm</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribusi Kelas Sesudah SMOTE&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0c4f22bff6e45816f354d5fbd5b70956d81cfa0542bf72acc8b628a86d3dd905.png" src="_images/0c4f22bff6e45816f354d5fbd5b70956d81cfa0542bf72acc8b628a86d3dd905.png" />
</div>
</div>
<section id="pca-dengan-smote">
<h3>PCA dengan SMOTE<a class="headerlink" href="#pca-dengan-smote" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Encode label kategori jadi angka</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_sm_encoded</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_sm</span><span class="p">)</span>

<span class="c1"># Lakukan PCA ke 2 dimensi</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_sm_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_sm</span><span class="p">)</span>

<span class="c1"># Plot hasil PCA sesudah SMOTE</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">X_sm_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">X_sm_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">c</span><span class="o">=</span><span class="n">y_sm_encoded</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;tab10&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span>
<span class="p">)</span>

<span class="c1"># Buat legenda otomatis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
    <span class="o">*</span><span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Kelas&quot;</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Sesudah SMOTE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5731467ea6976a1e3238a1c23b992e41fcdf24bad26c1c4f087c4d96285d1942.png" src="_images/5731467ea6976a1e3238a1c23b992e41fcdf24bad26c1c4f087c4d96285d1942.png" />
</div>
</div>
</section>
<section id="naive-bayes-data-seimbang-smote">
<h3><strong>Naive Bayes – Data Seimbang (SMOTE)</strong><a class="headerlink" href="#naive-bayes-data-seimbang-smote" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>SMOTE</strong>, model <strong>Naive Bayes (GaussianNB)</strong> digunakan kembali untuk klasifikasi.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil SMOTE menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Naive Bayes pada data latih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data SMOTE</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_sm</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi Naive Bayes dengan smoothing</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">(</span><span class="n">var_smoothing</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Naive Bayes (SMOTE):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Naive Bayes (SMOTE): 0.8078602620087336

Classification Report:
               precision    recall  f1-score   support

          cp       0.90      0.96      0.93        28
          im       0.49      0.93      0.64        28
         imL       0.97      1.00      0.98        29
         imS       1.00      1.00      1.00        29
         imU       1.00      0.03      0.07        29
          om       0.89      0.61      0.72        28
         omL       1.00      1.00      1.00        29
          pp       0.71      0.93      0.81        29

    accuracy                           0.81       229
   macro avg       0.87      0.81      0.77       229
weighted avg       0.87      0.81      0.77       229


Confusion Matrix:
 [[27  1  0  0  0  0  0  0]
 [ 1 26  1  0  0  0  0  0]
 [ 0  0 29  0  0  0  0  0]
 [ 0  0  0 29  0  0  0  0]
 [ 0 26  0  0  1  2  0  0]
 [ 0  0  0  0  0 17  0 11]
 [ 0  0  0  0  0  0 29  0]
 [ 2  0  0  0  0  0  0 27]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-data-seimbang-smote">
<h3><strong>Random Forest – Data Seimbang (SMOTE)</strong><a class="headerlink" href="#random-forest-data-seimbang-smote" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>SMOTE</strong>, model <strong>Random Forest Classifier</strong> digunakan untuk klasifikasi.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil SMOTE menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Random Forest pada data latih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data SMOTE</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_sm</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi Random Forest</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Random Forest (SMOTE):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Random Forest (SMOTE): 0.9737991266375546

Classification Report:
               precision    recall  f1-score   support

          cp       0.90      1.00      0.95        28
          im       0.93      0.93      0.93        28
         imL       0.97      1.00      0.98        29
         imS       1.00      1.00      1.00        29
         imU       1.00      0.93      0.96        29
          om       1.00      1.00      1.00        28
         omL       1.00      1.00      1.00        29
          pp       1.00      0.93      0.96        29

    accuracy                           0.97       229
   macro avg       0.97      0.97      0.97       229
weighted avg       0.98      0.97      0.97       229


Confusion Matrix:
 [[28  0  0  0  0  0  0  0]
 [ 1 26  1  0  0  0  0  0]
 [ 0  0 29  0  0  0  0  0]
 [ 0  0  0 29  0  0  0  0]
 [ 0  2  0  0 27  0  0  0]
 [ 0  0  0  0  0 28  0  0]
 [ 0  0  0  0  0  0 29  0]
 [ 2  0  0  0  0  0  0 27]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="bagging-classifier-data-seimbang-smote">
<h3><strong>Bagging Classifier – Data Seimbang (SMOTE)</strong><a class="headerlink" href="#bagging-classifier-data-seimbang-smote" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>SMOTE</strong>, model <strong>Bagging Classifier</strong> digunakan untuk klasifikasi.<br />
Dua skenario diuji:</p>
<ol class="arabic simple">
<li><p>Bagging dengan <strong>Naive Bayes</strong> sebagai base estimator.</p></li>
<li><p>Bagging dengan <strong>Decision Tree</strong> sebagai base estimator.</p></li>
</ol>
<p>Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil SMOTE menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Bagging dengan estimator terpilih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<section id="id1">
<h4>Bagging dengan Naive Bayes<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bagging dengan Naive Bayes</span>
<span class="n">bag_nb</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(</span><span class="n">var_smoothing</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">bag_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (Naive Bayes, SMOTE):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (Naive Bayes, SMOTE): 0.8034934497816594

Classification Report:
               precision    recall  f1-score   support

          cp       0.90      0.96      0.93        28
          im       0.47      0.93      0.63        28
         imL       0.97      1.00      0.98        29
         imS       1.00      0.93      0.96        29
         imU       1.00      0.03      0.07        29
          om       0.90      0.64      0.75        28
         omL       1.00      1.00      1.00        29
          pp       0.73      0.93      0.82        29

    accuracy                           0.80       229
   macro avg       0.87      0.80      0.77       229
weighted avg       0.87      0.80      0.77       229


Confusion Matrix:
 [[27  1  0  0  0  0  0  0]
 [ 1 26  1  0  0  0  0  0]
 [ 0  0 29  0  0  0  0  0]
 [ 0  2  0 27  0  0  0  0]
 [ 0 26  0  0  1  2  0  0]
 [ 0  0  0  0  0 18  0 10]
 [ 0  0  0  0  0  0 29  0]
 [ 2  0  0  0  0  0  0 27]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h4>Bagging dengan Decision Tree<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bagging dengan Decision Tree</span>
<span class="n">bag_dt</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">bag_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (Decision Tree, SMOTE):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (Decision Tree, SMOTE): 0.9650655021834061

Classification Report:
               precision    recall  f1-score   support

          cp       0.90      0.96      0.93        28
          im       0.93      0.93      0.93        28
         imL       0.94      1.00      0.97        29
         imS       1.00      1.00      1.00        29
         imU       1.00      0.93      0.96        29
          om       0.97      1.00      0.98        28
         omL       1.00      1.00      1.00        29
          pp       1.00      0.90      0.95        29

    accuracy                           0.97       229
   macro avg       0.97      0.97      0.96       229
weighted avg       0.97      0.97      0.97       229


Confusion Matrix:
 [[27  1  0  0  0  0  0  0]
 [ 1 26  1  0  0  0  0  0]
 [ 0  0 29  0  0  0  0  0]
 [ 0  0  0 29  0  0  0  0]
 [ 0  1  1  0 27  0  0  0]
 [ 0  0  0  0  0 28  0  0]
 [ 0  0  0  0  0  0 29  0]
 [ 2  0  0  0  0  1  0 26]]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="eksperimen-3-adasyn">
<h2><strong>3. Eksperimen 3 – ADASYN</strong><a class="headerlink" href="#eksperimen-3-adasyn" title="Link to this heading">#</a></h2>
<p>Pada eksperimen ini digunakan teknik <strong>ADASYN (Adaptive Synthetic Sampling)</strong> untuk menyeimbangkan data.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Pisahkan fitur (X) dan label (y).</p></li>
<li><p>Terapkan ADASYN dengan variasi parameter <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> sesuai distribusi kelas.</p></li>
<li><p>Simpan hasil akhir dataset seimbang untuk digunakan dalam klasifikasi (Naive Bayes, Random Forest, dan Bagging).</p></li>
<li><p>Tampilkan distribusi kelas sebelum dan sesudah ADASYN.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">naive_bayes</span> <span class="o">=</span> <span class="n">df</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">naive_bayes</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="s2">&quot;sequence_name&quot;</span><span class="p">])</span>  <span class="c1"># fitur numerik</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">naive_bayes</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi kelas awal:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

<span class="n">class_counts</span> <span class="o">=</span> <span class="p">[</span><span class="n">count</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
<span class="n">temp</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)</span>

<span class="n">nt</span><span class="p">,</span> <span class="n">ns</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>  <span class="c1"># salin awal</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sorted counts untuk iterasi: </span><span class="si">{</span><span class="n">temp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">temp</span><span class="p">))):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">temp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># n_neighbors tidak boleh &lt; 1</span>
    <span class="c1"># print(f&quot;\nIterasi {i+1}: menggunakan k_neighbors={n}&quot;)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">sampler</span> <span class="o">=</span> <span class="n">ADASYN</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">sampling_strategy</span><span class="o">=</span><span class="s1">&#39;minority&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">nt</span><span class="p">,</span> <span class="n">ns</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">nt</span><span class="p">,</span> <span class="n">ns</span><span class="p">)</span>
        <span class="c1"># print(f&quot;Hasil iterasi {i+1}: {sorted(Counter(ns).items())}&quot;)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error pada iterasi </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">break</span>

<span class="c1"># ==========================</span>
<span class="c1"># 4. Hasil akhir</span>
<span class="c1"># ==========================</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi kelas setelah ADASYN:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Total samples sebelum: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total samples setelah: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data yang ditambahkan: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribusi kelas awal:
[(&#39;cp&#39;, 143), (&#39;im&#39;, 77), (&#39;imL&#39;, 2), (&#39;imS&#39;, 2), (&#39;imU&#39;, 35), (&#39;om&#39;, 20), (&#39;omL&#39;, 5), (&#39;pp&#39;, 52)]

Sorted counts untuk iterasi: [2, 2, 5, 20, 35, 52, 77, 143]

Distribusi kelas setelah ADASYN:
[(&#39;cp&#39;, 143), (&#39;im&#39;, 154), (&#39;imL&#39;, 142), (&#39;imS&#39;, 142), (&#39;imU&#39;, 146), (&#39;om&#39;, 143), (&#39;omL&#39;, 143), (&#39;pp&#39;, 146)]

Total samples sebelum: 336
Total samples setelah: 1159
Data yang ditambahkan: 823
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Sebelum ADASYN</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribusi Kelas Sebelum ADASYN&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="c1"># Sesudah ADASYN</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribusi Kelas Sesudah ADASYN&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c24ff2434fd329999d4deb703ad6251cf230052c5323358f6c146cf767a2338d.png" src="_images/c24ff2434fd329999d4deb703ad6251cf230052c5323358f6c146cf767a2338d.png" />
</div>
</div>
<section id="pca-sesudah-adasyn">
<h3>PCA sesudah ADASYN<a class="headerlink" href="#pca-sesudah-adasyn" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Encode label kategori (supaya bisa diberi warna)</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">ns_encoded</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>

<span class="c1"># PCA ke 2 dimensi (fitur hasil ADASYN = nt)</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_ns_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">nt</span><span class="p">)</span>

<span class="c1"># Scatter plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">X_ns_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">X_ns_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">c</span><span class="o">=</span><span class="n">ns_encoded</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;tab10&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span>
<span class="p">)</span>

<span class="c1"># Tambahkan legenda</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">*</span><span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Kelas&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Sesudah ADASYN&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9789eadc809eaccd767706e8baa37dabe2acb5e48bbac6e150edcf6834c4d47.png" src="_images/b9789eadc809eaccd767706e8baa37dabe2acb5e48bbac6e150edcf6834c4d47.png" />
</div>
</div>
</section>
<section id="naive-bayes-data-seimbang-adasyn">
<h3><strong>Naive Bayes – Data Seimbang (ADASYN)</strong><a class="headerlink" href="#naive-bayes-data-seimbang-adasyn" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>ADASYN</strong>, model <strong>Naive Bayes (GaussianNB)</strong> digunakan untuk klasifikasi.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil ADASYN menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Naive Bayes pada data latih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data ADASYN</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">nt</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">ns</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi Naive Bayes</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Latih model</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Naive Bayes (ADASYN):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Naive Bayes (ADASYN): 0.7931034482758621

Classification Report:
               precision    recall  f1-score   support

          cp       0.84      0.98      0.90        43
          im       0.50      0.91      0.65        46
         imL       0.98      1.00      0.99        43
         imS       1.00      0.98      0.99        42
         imU       1.00      0.02      0.04        44
          om       0.89      0.56      0.69        43
         omL       1.00      1.00      1.00        43
          pp       0.69      0.91      0.78        44

    accuracy                           0.79       348
   macro avg       0.86      0.79      0.76       348
weighted avg       0.86      0.79      0.75       348


Confusion Matrix:
 [[42  1  0  0  0  0  0  0]
 [ 2 42  1  0  0  1  0  0]
 [ 0  0 43  0  0  0  0  0]
 [ 0  1  0 41  0  0  0  0]
 [ 1 40  0  0  1  2  0  0]
 [ 1  0  0  0  0 24  0 18]
 [ 0  0  0  0  0  0 43  0]
 [ 4  0  0  0  0  0  0 40]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-data-seimbang-adasyn">
<h3><strong>Random Forest – Data Seimbang (ADASYN)</strong><a class="headerlink" href="#random-forest-data-seimbang-adasyn" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>ADASYN</strong>, model <strong>Random Forest</strong> digunakan untuk klasifikasi.<br />
Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil ADASYN menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Random Forest pada data latih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split data ADASYN (sudah sama seperti sebelumnya, jadi bisa pakai ulang)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">nt</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">ns</span>
<span class="p">)</span>

<span class="c1"># Inisialisasi Random Forest</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Latih model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Random Forest (ADASYN):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Random Forest (ADASYN): 0.9525862068965517
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification Report:
               precision    recall  f1-score   support

          cp       0.88      1.00      0.94        29
          im       0.90      0.90      0.90        31
         imL       0.97      1.00      0.98        28
         imS       1.00      1.00      1.00        28
         imU       0.96      0.90      0.93        29
          om       0.97      0.97      0.97        29
         omL       1.00      1.00      1.00        29
          pp       0.96      0.86      0.91        29

    accuracy                           0.95       232
   macro avg       0.95      0.95      0.95       232
weighted avg       0.95      0.95      0.95       232


Confusion Matrix:
 [[29  0  0  0  0  0  0  0]
 [ 1 28  1  0  1  0  0  0]
 [ 0  0 28  0  0  0  0  0]
 [ 0  0  0 28  0  0  0  0]
 [ 0  3  0  0 26  0  0  0]
 [ 0  0  0  0  0 28  0  1]
 [ 0  0  0  0  0  0 29  0]
 [ 3  0  0  0  0  1  0 25]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="bagging-classifier-data-seimbang-adasyn">
<h3><strong>Bagging Classifier – Data Seimbang (ADASYN)</strong><a class="headerlink" href="#bagging-classifier-data-seimbang-adasyn" title="Link to this heading">#</a></h3>
<p>Setelah dataset diseimbangkan menggunakan <strong>ADASYN</strong>, model <strong>Bagging Classifier</strong> digunakan untuk klasifikasi.<br />
Dua skenario diuji:</p>
<ol class="arabic simple">
<li><p>Bagging dengan <strong>Naive Bayes</strong> sebagai base estimator.</p></li>
<li><p>Bagging dengan <strong>Decision Tree</strong> sebagai base estimator.</p></li>
</ol>
<p>Langkah-langkah:</p>
<ol class="arabic simple">
<li><p>Bagi dataset hasil ADASYN menjadi data latih (train) dan data uji (test).</p></li>
<li><p>Latih model Bagging pada data latih.</p></li>
<li><p>Evaluasi performa model dengan data uji menggunakan akurasi, classification report, dan confusion matrix.</p></li>
</ol>
<section id="id3">
<h4>Bagging dengan Naive Bayes<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bagging dengan Naive Bayes</span>
<span class="n">bag_nb</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">bag_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (Naive Bayes, ADASYN):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (Naive Bayes, ADASYN): 0.7801724137931034

Classification Report:
               precision    recall  f1-score   support

          cp       0.85      1.00      0.92        29
          im       0.50      0.87      0.64        31
         imL       0.97      1.00      0.98        28
         imS       1.00      1.00      1.00        28
         imU       1.00      0.03      0.07        29
          om       0.87      0.45      0.59        29
         omL       1.00      1.00      1.00        29
          pp       0.62      0.90      0.73        29

    accuracy                           0.78       232
   macro avg       0.85      0.78      0.74       232
weighted avg       0.85      0.78      0.74       232


Confusion Matrix:
 [[29  0  0  0  0  0  0  0]
 [ 2 27  1  0  0  1  0  0]
 [ 0  0 28  0  0  0  0  0]
 [ 0  0  0 28  0  0  0  0]
 [ 0 27  0  0  1  1  0  0]
 [ 0  0  0  0  0 13  0 16]
 [ 0  0  0  0  0  0 29  0]
 [ 3  0  0  0  0  0  0 26]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h4>Bagging dengan Decision Tree<a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bagging dengan Decision Tree</span>
<span class="n">bag_dt</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">bag_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🔹 Akurasi Bagging (Decision Tree, ADASYN):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🔹 Akurasi Bagging (Decision Tree, ADASYN): 0.9439655172413793

Classification Report:
               precision    recall  f1-score   support

          cp       0.88      1.00      0.94        29
          im       0.93      0.84      0.88        31
         imL       0.93      1.00      0.97        28
         imS       1.00      1.00      1.00        28
         imU       0.90      0.90      0.90        29
          om       0.97      0.97      0.97        29
         omL       1.00      1.00      1.00        29
          pp       0.96      0.86      0.91        29

    accuracy                           0.94       232
   macro avg       0.95      0.95      0.94       232
weighted avg       0.95      0.94      0.94       232


Confusion Matrix:
 [[29  0  0  0  0  0  0  0]
 [ 1 26  1  0  3  0  0  0]
 [ 0  0 28  0  0  0  0  0]
 [ 0  0  0 28  0  0  0  0]
 [ 0  2  1  0 26  0  0  0]
 [ 0  0  0  0  0 28  0  1]
 [ 0  0  0  0  0  0 29  0]
 [ 3  0  0  0  0  1  0 25]]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="perbandingan-hasil-klasifikasi-data-asli-vs-smote-vs-adasyn">
<h2>Perbandingan Hasil Klasifikasi – Data Asli vs SMOTE vs ADASYN<a class="headerlink" href="#perbandingan-hasil-klasifikasi-data-asli-vs-smote-vs-adasyn" title="Link to this heading">#</a></h2>
<p>Tabel berikut membandingkan performa model <strong>Naive Bayes, Random Forest, dan Bagging</strong> pada tiga kondisi data:</p>
<ul class="simple">
<li><p><strong>Asli (belum diseimbangkan)</strong></p></li>
<li><p><strong>SMOTE (Synthetic Minority Oversampling Technique)</strong></p></li>
<li><p><strong>ADASYN (Adaptive Synthetic Sampling)</strong></p></li>
</ul>
<p>Metrik yang digunakan:</p>
<ul class="simple">
<li><p><strong>Accuracy</strong></p></li>
<li><p><strong>Macro F1-score</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">f1_score</span>

<span class="c1"># Reset results</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_model</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_tr</span><span class="p">,</span> <span class="n">X_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span><span class="p">,</span> <span class="n">dataset_label</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;Model&quot;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span>
        <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span> <span class="n">dataset_label</span><span class="p">,</span>
        <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
        <span class="s2">&quot;Macro F1&quot;</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="p">})</span>

<span class="c1"># =============================</span>
<span class="c1"># 1. Data Asli</span>
<span class="c1"># =============================</span>
<span class="n">X_train0</span><span class="p">,</span> <span class="n">X_test0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">,</span> <span class="n">y_test0</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Naive Bayes&quot;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">X_train0</span><span class="p">,</span> <span class="n">X_test0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">,</span> <span class="n">y_test0</span><span class="p">,</span> <span class="s2">&quot;Asli&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train0</span><span class="p">,</span> <span class="n">X_test0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">,</span> <span class="n">y_test0</span><span class="p">,</span> <span class="s2">&quot;Asli&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (NB)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train0</span><span class="p">,</span> <span class="n">X_test0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">,</span> <span class="n">y_test0</span><span class="p">,</span> <span class="s2">&quot;Asli&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (DT)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train0</span><span class="p">,</span> <span class="n">X_test0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">,</span> <span class="n">y_test0</span><span class="p">,</span> <span class="s2">&quot;Asli&quot;</span><span class="p">)</span>

<span class="c1"># =============================</span>
<span class="c1"># 2. Data SMOTE</span>
<span class="c1"># =============================</span>
<span class="n">X_train1</span><span class="p">,</span> <span class="n">X_test1</span><span class="p">,</span> <span class="n">y_train1</span><span class="p">,</span> <span class="n">y_test1</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_sm</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Naive Bayes&quot;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">X_test1</span><span class="p">,</span> <span class="n">y_train1</span><span class="p">,</span> <span class="n">y_test1</span><span class="p">,</span> <span class="s2">&quot;SMOTE&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">X_test1</span><span class="p">,</span> <span class="n">y_train1</span><span class="p">,</span> <span class="n">y_test1</span><span class="p">,</span> <span class="s2">&quot;SMOTE&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (NB)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">X_test1</span><span class="p">,</span> <span class="n">y_train1</span><span class="p">,</span> <span class="n">y_test1</span><span class="p">,</span> <span class="s2">&quot;SMOTE&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (DT)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train1</span><span class="p">,</span> <span class="n">X_test1</span><span class="p">,</span> <span class="n">y_train1</span><span class="p">,</span> <span class="n">y_test1</span><span class="p">,</span> <span class="s2">&quot;SMOTE&quot;</span><span class="p">)</span>

<span class="c1"># =============================</span>
<span class="c1"># 3. Data ADASYN</span>
<span class="c1"># =============================</span>
<span class="n">X_train2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_test2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">nt</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Naive Bayes&quot;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">X_train2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_test2</span><span class="p">,</span> <span class="s2">&quot;ADASYN&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_test2</span><span class="p">,</span> <span class="s2">&quot;ADASYN&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (NB)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_test2</span><span class="p">,</span> <span class="s2">&quot;ADASYN&quot;</span><span class="p">)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="s2">&quot;Bagging (DT)&quot;</span><span class="p">,</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">X_train2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_test2</span><span class="p">,</span> <span class="s2">&quot;ADASYN&quot;</span><span class="p">)</span>

<span class="c1"># =============================</span>
<span class="c1"># Hasil ke DataFrame</span>
<span class="c1"># =============================</span>
<span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">df_results_pivot</span> <span class="o">=</span> <span class="n">df_results</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Macro F1&quot;</span><span class="p">])</span>
<span class="n">df_results_pivot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
/home/codespace/.local/lib/python3.12/site-packages/sklearn/naive_bayes.py:512: RuntimeWarning: divide by zero encountered in log
  jointi = np.log(self.class_prior_[i])
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">Accuracy</th>
      <th colspan="3" halign="left">Macro F1</th>
    </tr>
    <tr>
      <th>Dataset</th>
      <th>ADASYN</th>
      <th>Asli</th>
      <th>SMOTE</th>
      <th>ADASYN</th>
      <th>Asli</th>
      <th>SMOTE</th>
    </tr>
    <tr>
      <th>Model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bagging (DT)</th>
      <td>0.9440</td>
      <td>0.8824</td>
      <td>0.9651</td>
      <td>0.9442</td>
      <td>0.8193</td>
      <td>0.9648</td>
    </tr>
    <tr>
      <th>Bagging (NB)</th>
      <td>0.7802</td>
      <td>0.8382</td>
      <td>0.7817</td>
      <td>0.7410</td>
      <td>0.7343</td>
      <td>0.7421</td>
    </tr>
    <tr>
      <th>Naive Bayes</th>
      <td>0.7845</td>
      <td>0.8529</td>
      <td>0.7904</td>
      <td>0.7443</td>
      <td>0.7561</td>
      <td>0.7485</td>
    </tr>
    <tr>
      <th>Random Forest</th>
      <td>0.9526</td>
      <td>0.8971</td>
      <td>0.9738</td>
      <td>0.9530</td>
      <td>0.8586</td>
      <td>0.9737</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="preposesing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Preprocessing</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-machine-learning">Model Machine Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library">Import Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemanggilan-data-ecoli-dari-database-aiven">Pemanggilan data ecoli dari database Aiven</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-awal-distribusi-kelas">Eksplorasi Awal &amp; Distribusi Kelas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persiapan-data">Persiapan Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-1-data-belum-diseimbangkan">1. <strong>Eksperimen 1 – Data Belum Diseimbangkan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-belum-diseimbangkan"><strong>Naive Bayes – Data Belum Diseimbangkan</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-belum-diseimbangkan"><strong>Random Forest – Data Belum Diseimbangkan</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-belum-diseimbangkan"><strong>Bagging Classifier – Data Belum Diseimbangkan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-dengan-naive-bayes">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-dengan-decision-tree">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-2-data-seimbang-dengan-smote"><strong>2. Eksperimen 2 – Data Seimbang dengan SMOTE</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-dengan-smote">PCA dengan SMOTE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-seimbang-smote"><strong>Naive Bayes – Data Seimbang (SMOTE)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-seimbang-smote"><strong>Random Forest – Data Seimbang (SMOTE)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-seimbang-smote"><strong>Bagging Classifier – Data Seimbang (SMOTE)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksperimen-3-adasyn"><strong>3. Eksperimen 3 – ADASYN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-sesudah-adasyn">PCA sesudah ADASYN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-data-seimbang-adasyn"><strong>Naive Bayes – Data Seimbang (ADASYN)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-data-seimbang-adasyn"><strong>Random Forest – Data Seimbang (ADASYN)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-classifier-data-seimbang-adasyn"><strong>Bagging Classifier – Data Seimbang (ADASYN)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Bagging dengan Naive Bayes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Bagging dengan Decision Tree</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-hasil-klasifikasi-data-asli-vs-smote-vs-adasyn">Perbandingan Hasil Klasifikasi – Data Asli vs SMOTE vs ADASYN</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>